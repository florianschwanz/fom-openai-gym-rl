{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from itertools import count\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Make library available in path\n",
    "!git clone https://github.com/fom-big-data/fom-openai-gym-rl\n",
    "lib_path = os.path.join(os.getcwd(), 'fom-openai-gym-rl', 'notebooks', '00-basemodel', 'atari-dqn', 'lib')\n",
    "if not (lib_path in sys.path):\n",
    "    sys.path.insert(0, lib_path)\n",
    "\n",
    "# Import library classes\n",
    "from replay_memory import ReplayMemory\n",
    "from deep_q_network import DeepQNetwork\n",
    "from action_selector import ActionSelector\n",
    "from input_extractor import InputExtractor\n",
    "from model_optimizer import ModelOptimizer\n",
    "from environment_enum import Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0 Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ENVIRONMENT_NAME = Environment.PONG_v0\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "REPLAY_MEMORY_SIZE = 10000\n",
    "NUM_EPISODES = 50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0.1 Configure device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0.2 Set up matplotlib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Enable interactive mode of matplotlib\n",
    "plt.ion()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0.3 Set up TensorBoard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0.4 Set up environment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize environment\n",
    "env = gym.make(ENVIRONMENT_NAME.value).unwrapped\n",
    "# Reset environment\n",
    "env.reset()\n",
    "# Plot initial screen\n",
    "InputExtractor.plot_screen(InputExtractor.get_sharp_screen(env=env, device=device), 'Example extracted screen')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 Set up nets\n",
    "\n",
    "# 1.1 Define nets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = InputExtractor.get_screen(env=env, device=device)\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# Initialize policy net and target net\n",
    "policy_net = DeepQNetwork(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DeepQNetwork(screen_height, screen_width, n_actions).to(device)\n",
    "\n",
    "# Since both nets are initialized randomly we need to copy the state of one into the other to make sure they are equal\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.2 Define optimizer and replay memory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "# Initialize replay memory\n",
    "memory = ReplayMemory(REPLAY_MEMORY_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "episode_durations = []\n",
    "episode_losses = []\n",
    "episode_rewards = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.1 Display TensorBoard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize writer\n",
    "tensorboard_summary_writer = SummaryWriter()\n",
    "%tensorboard --logdir=runs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.2 Training loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Iterate over episodes\n",
    "for i_episode in range(NUM_EPISODES):\n",
    "\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = InputExtractor.get_screen(env=env, device=device)\n",
    "    current_screen = InputExtractor.get_screen(env=env, device=device)\n",
    "    state = current_screen - last_screen\n",
    "    \n",
    "    # Run episode until status done is reached\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = ActionSelector.select_action(state=state,\n",
    "                                              n_actions=n_actions,\n",
    "                                              policy_net=policy_net,\n",
    "                                              epsilon_end=EPS_END,\n",
    "                                              epsilon_start=EPS_START,\n",
    "                                              epsilon_decay=EPS_DECAY,\n",
    "                                              device=device)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "\n",
    "        # Transform reward into a tensor\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = InputExtractor.get_screen(env=env, device=device)\n",
    "        \n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        loss = ModelOptimizer.optimize_model(policy_net=policy_net,\n",
    "                                      target_net=target_net,\n",
    "                                      optimizer=optimizer,\n",
    "                                      memory=memory,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      gamma=GAMMA,\n",
    "                                      device=device)\n",
    "\n",
    "        # Plot performance once the episode is done\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "\n",
    "            if loss is None:\n",
    "                print(\"Episode  \" + str(i_episode+1) + \" (\" + str(t) + \" frames) reward \" + str(reward.item()))\n",
    "            else:\n",
    "                print(\"Episode  \" + str(i_episode+1) + \" (\" + str(t) + \" frames) reward \"\n",
    "                      + str(reward.item()) + \" loss \" + str(loss.item()))\n",
    "                episode_losses.append(loss.item())\n",
    "            break\n",
    "\n",
    "    # Update the target network, copying all weights and biases from policy net into target net\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}